{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simafaramarzi/MNIST-Digit-Recognition-A-Neural-Network-Approach-with-ReLU-and-Tanh/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMag7qXbIF9b"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXbWo3BkQrLS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf                                # To build and train machine learning models\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist            # Importing MINST data set\n",
        "from tensorflow.keras.models import Sequential         # Importing Sequential Model\n",
        "from tensorflow.keras.layers import Dense, Flatten     # Importing Layers\n",
        "from tensorflow.keras.utils import to_categorical      # Convert numeric labels to vectors one-hot\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import Input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs8xlZM5dmxQ"
      },
      "outputs": [],
      "source": [
        "# Loading Dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Display data shapes\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Test data shape:\", x_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG2N_17VWE-N"
      },
      "outputs": [],
      "source": [
        "# Display sample images\n",
        "def show_sample_images(X, y, n=10):\n",
        "    plt.figure(figsize=(10,2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1,n,i+1)\n",
        "        plt.imshow(X[i], cmap='gray')\n",
        "        plt.title(f\"Label: {y[i]}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEShJ4iNfKsc"
      },
      "outputs": [],
      "source": [
        "# If you intend to use ReLU, use the range [0, 1]\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Converting labels to one-hot\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjtYp-lHXIYe"
      },
      "outputs": [],
      "source": [
        "def build_model(activation_fn):                               # Definition of a function\n",
        "    model = Sequential()                                      # A simple linear model in Keras\n",
        "    model.add(Flatten(input_shape=(28, 28)))                  # reshape\n",
        "    model.add(Dense(128, activation=activation_fn))           # creating the first layer\n",
        "    model.add(Dense(64, activation=activation_fn))            # creating the second layer\n",
        "    model.add(Dense(32, activation=activation_fn))            # creating the third layer\n",
        "    model.add(Dense(10, activation='softmax'))                # Probability output\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])   # compiling\n",
        "    return model\n",
        "model_relu = build_model('relu')     # calling\n",
        "model_relu.summary()                 # summurizing\n",
        "\n",
        "history_relu = model_relu.fit(x_train, y_train_cat, epochs=10, validation_data=(x_test, y_test_cat), verbose=2)   # Training\n",
        "\n",
        "# Prediction and evaluation of the ReLU model\n",
        "y_pred_prob_relu = model_relu.predict(x_test)\n",
        "y_pred_relu = np.argmax(y_pred_prob_relu, axis=1)\n",
        "accuracy_relu = np.sum(y_pred_relu == y_test) / len(y_test)\n",
        "print(f\"Accuracy with ReLU: {accuracy_relu:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fDfh9HMXQKn"
      },
      "outputs": [],
      "source": [
        "model_tanh = build_model('tanh')\n",
        "model_tanh.summary()\n",
        "history_tanh = model_tanh.fit(x_train, y_train_cat, epochs=10, validation_data=(x_test, y_test_cat), verbose=2)\n",
        "\n",
        "# Prediction and evaluation of the Tanh model\n",
        "y_pred_prob_tanh = model_tanh.predict(x_test)\n",
        "y_pred_tanh = np.argmax(y_pred_prob_tanh, axis=1)\n",
        "accuracy_tanh = np.sum(y_pred_tanh == y_test) / len(y_test)\n",
        "print(f\"Accuracy with Tanh: {accuracy_tanh:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-tnmStUYM4L"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "def plot_confusion(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(5,5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f'Confusion Matrix - {title}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion(y_test, y_pred_relu, \"ReLU\")\n",
        "plot_confusion(y_test, y_pred_tanh, \"Tanh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEAxO_16gf3s"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, activation_name):\n",
        "    # Training Accuracy and Validation\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'Accuracy - Activation: {activation_name}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Loss during training and validation\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Loss - Activation: {activation_name}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_relu, 'ReLU')\n",
        "plot_history(history_tanh, 'Tanh')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdD6tZacgjii"
      },
      "outputs": [],
      "source": [
        "# Displaying Examples of Mistake\n",
        "def show_misclassified(X, y_true, y_pred, n=5):\n",
        "    wrong = np.where(y_true != y_pred)[0]                 #Comparison of true labels with predicted labels\n",
        "    plt.figure(figsize=(5,5))\n",
        "    for i, idx in enumerate(wrong[:n]):\n",
        "        plt.subplot(3,3,i+1)\n",
        "        plt.imshow(X[idx], cmap='gray')                    # print lables\n",
        "        plt.title(f\"True: {y_true[idx]}\\nPred: {y_pred[idx]}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(\"Misclassified Digits\", y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "show_misclassified(x_test, y_test, y_pred_relu)          #Mistakes of each model should be displayed separately.\n",
        "show_misclassified(x_test, y_test, y_pred_tanh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oQRX-dWYMTA"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf                     # To build and train machine learning models\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist            # Importing MINST data set\n",
        "from tensorflow.keras.models import Sequential         # Importing Sequential Model\n",
        "from tensorflow.keras.layers import Dense, Flatten     # Importing Layers\n",
        "from tensorflow.keras.utils import to_categorical      # Convert numeric labels to vectors one-hot\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import Input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Loading Dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Display data shapes\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Test data shape:\", x_test.shape)\n",
        "# Display sample images\n",
        "def show_sample_images(X, y, n=10):\n",
        "    plt.figure(figsize=(10,2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1,n,i+1)\n",
        "        plt.imshow(X[i], cmap='gray')\n",
        "        plt.title(f\"Label: {y[i]}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images(x_train, y_train)\n",
        "# If you intend to use ReLU, use the range [0, 1]\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Converting labels to one-hot\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "def build_model(activation_fn):                               # Definition of a function\n",
        "    model = Sequential()                                      # A simple linear model in Keras\n",
        "    model.add(Flatten(input_shape=(28, 28)))                  # reshape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model.add(Dense(128, activation=activation_fn))           # creating the first layer\n",
        "    model.add(Dense(64, activation=activation_fn))            # creating the second layer\n",
        "    model.add(Dense(32, activation=activation_fn))            # creating the third layer\n",
        "    model.add(Dense(10, activation='softmax'))                # Probability output\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])   # compiling\n",
        "    return model\n",
        "\n",
        "model_relu = build_model('relu')     # calling\n",
        "model_relu.summary()                 # summurizing\n",
        "\n",
        "history_relu = model_relu.fit(x_train, y_train_cat, epochs=10, validation_data=(x_test, y_test_cat), verbose=2)   # Training\n",
        "\n",
        "# Prediction and evaluation of the ReLU model\n",
        "y_pred_prob_relu = model_relu.predict(x_test)\n",
        "y_pred_relu = np.argmax(y_pred_prob_relu, axis=1)\n",
        "accuracy_relu = np.sum(y_pred_relu == y_test) / len(y_test)\n",
        "print(f\"Accuracy with ReLU: {accuracy_relu:.4f}\")\n",
        "model_tanh = build_model('tanh')\n",
        "model_tanh.summary()\n",
        "history_tanh = model_tanh.fit(x_train, y_train_cat, epochs=10, validation_data=(x_test, y_test_cat), verbose=2)\n",
        "\n",
        "# Prediction and evaluation of the Tanh model\n",
        "y_pred_prob_tanh = model_tanh.predict(x_test)\n",
        "y_pred_tanh = np.argmax(y_pred_prob_tanh, axis=1)\n",
        "accuracy_tanh = np.sum(y_pred_tanh == y_test) / len(y_test)\n",
        "print(f\"Accuracy with Tanh: {accuracy_tanh:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "def plot_confusion(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(5,5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f'Confusion Matrix - {title}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion(y_test, y_pred_relu, \"ReLU\")\n",
        "plot_confusion(y_test, y_pred_tanh, \"Tanh\")\n",
        "def plot_history(history, activation_name):\n",
        "    # Training Accuracy and Validation\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'Accuracy - Activation: {activation_name}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Loss during training and validation\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Loss - Activation: {activation_name}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history_relu, 'ReLU')\n",
        "plot_history(history_tanh, 'Tanh')\n",
        "# Displaying Examples of Mistake\n",
        "def show_misclassified(X, y_true, y_pred, n=5):\n",
        "    wrong = np.where(y_true != y_pred)[0]                 #Comparison of true labels with predicted labels\n",
        "    plt.figure(figsize=(5,5))\n",
        "    for i, idx in enumerate(wrong[:n]):\n",
        "        plt.subplot(3,3,i+1)\n",
        "        plt.imshow(X[idx], cmap='gray')                    # print lables\n",
        "        plt.title(f\"True: {y_true[idx]}\\nPred: {y_pred[idx]}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(\"Misclassified Digits\", y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "show_misclassified(x_test, y_test, y_pred_relu)          #Mistakes of each model should be displayed separately.\n",
        "show_misclassified(x_test, y_test, y_pred_tanh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zo9rwTQi6dcP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe365JjwcoHEVifTzELyTP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}